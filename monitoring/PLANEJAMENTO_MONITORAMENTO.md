# üìã Planejamento de Implementa√ß√£o: Monitoramento MLOps

**Projeto:** mlops-monitoring-prep  
**Data:** Novembro 2025  
**Objetivo:** Adicionar recursos de monitoramento (Loguru, Prometheus, Grafana) ao projeto acad√™mico de MLOps

---

## üìë √çNDICE - PASSOS DE EXECU√á√ÉO

### **PASSO 1: Prepara√ß√£o do Ambiente** ‚öôÔ∏è
- [1.1 Atualizar Depend√™ncias](#passo-1-prepara√ß√£o-do-ambiente)
- [1.2 Criar Estrutura de Diret√≥rios](#12-criar-estrutura-de-diret√≥rios)
- [1.3 Arquivos de Configura√ß√£o](#13-arquivos-de-configura√ß√£o)

### **PASSO 2: Implementa√ß√£o do Loguru** üìù
- [2.1 Criar M√≥dulo de Logging](#passo-2-implementa√ß√£o-do-loguru)
- [2.2 Integrar nos Scripts Existentes](#22-integrar-nos-scripts-existentes)
- [2.3 Definir Padr√µes de Logging](#23-definir-padr√µes-de-logging)

### **PASSO 3: Implementa√ß√£o do Prometheus** üìä
- [3.1 Criar M√≥dulo de M√©tricas](#passo-3-implementa√ß√£o-do-prometheus)
- [3.2 Instrumentar API FastAPI](#32-instrumentar-api-fastapi)
- [3.3 M√©tricas Customizadas](#33-m√©tricas-customizadas)
- [3.4 Container do Prometheus](#34-container-do-prometheus)

### **PASSO 4: Implementa√ß√£o do Grafana** üìà
- [4.1 Criar Container do Grafana](#passo-4-implementa√ß√£o-do-grafana)
- [4.2 Configurar Datasource Prometheus](#42-configurar-datasource-prometheus)
- [4.3 Criar Dashboards](#43-criar-dashboards)
- [4.4 Configurar Alertas](#44-configurar-alertas)

### **PASSO 5: M√©tricas de Machine Learning** ü§ñ
- [5.1 Instrumentar Treinamento](#passo-5-m√©tricas-de-machine-learning)
- [5.2 Instrumentar Predi√ß√£o](#52-instrumentar-predi√ß√£o)
- [5.3 M√©tricas de Neg√≥cio](#53-m√©tricas-de-neg√≥cio)

### **PASSO 6: Integra√ß√£o e Testes** ‚úÖ
- [6.1 Scripts de Inicializa√ß√£o](#passo-6-integra√ß√£o-e-testes)
- [6.2 Testes de Carga](#62-testes-de-carga)
- [6.3 Documenta√ß√£o](#63-documenta√ß√£o)
- [6.4 Exemplos Pr√°ticos](#64-exemplos-pr√°ticos)

---

## üéØ VIS√ÉO GERAL

### Stack de Monitoramento

| Ferramenta | Fun√ß√£o | Porta | Container |
|------------|--------|-------|-----------|
| **Loguru** | Logging estruturado | N/A | Biblioteca Python |
| **Prometheus** | Coleta de m√©tricas | 9090 | prometheus-server |
| **Grafana** | Visualiza√ß√£o | 3000 | grafana-server |
| **API FastAPI** | Aplica√ß√£o | 8000 | api-churn |

### Componentes do Sistema

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    APLICA√á√ïES PYTHON                         ‚îÇ
‚îÇ  [Treinamento] [Predi√ß√£o] [Retreinamento] [API FastAPI]    ‚îÇ
‚îÇ         ‚Üì            ‚Üì            ‚Üì            ‚Üì             ‚îÇ
‚îÇ    [Loguru] + [Prometheus Client] + [Custom Metrics]       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                 ‚îÇ                 ‚îÇ
        ‚ñº                 ‚ñº                 ‚ñº
  [Logs/*.log]    [/metrics endpoint]  [M√©tricas Custom]
        ‚îÇ                 ‚îÇ                 ‚îÇ
        ‚îÇ                 ‚îÇ                 ‚îÇ
        ‚îÇ                 ‚ñº                 ‚îÇ
        ‚îÇ         [Prometheus Server]       ‚îÇ
        ‚îÇ                 ‚îÇ                 ‚îÇ
        ‚îÇ                 ‚ñº                 ‚îÇ
        ‚îÇ           [Grafana Server]        ‚îÇ
        ‚îÇ                 ‚îÇ                 ‚îÇ
        ‚îÇ                 ‚ñº                 ‚îÇ
        ‚îÇ         [Dashboards Visuais]      ‚îÇ
        ‚îÇ                                   ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                Observabilidade Completa
```

---

## üìä M√âTRICAS DEFINIDAS

### M√©tricas de Infraestrutura da API

| M√©trica | Tipo | Descri√ß√£o | Dashboard |
|---------|------|-----------|-----------|
| `api_requests_total` | Counter | Total de requisi√ß√µes HTTP | API Health |
| `api_request_duration_seconds` | Histogram | Tempo de resposta | API Health |
| `api_errors_total` | Counter | Total de erros por c√≥digo | API Health |
| `api_active_requests` | Gauge | Requisi√ß√µes em andamento | API Health |
| `api_predictions_loaded` | Gauge | Predi√ß√µes em mem√≥ria | API Health |

### M√©tricas de Neg√≥cio (ML)

| M√©trica | Tipo | Descri√ß√£o | Dashboard |
|---------|------|-----------|-----------|
| `churn_predictions_high_risk` | Gauge | Clientes alto risco | Business |
| `churn_predictions_by_level` | Gauge | Por n√≠vel (baixo/m√©dio/alto) | Business |
| `churn_prediction_score_avg` | Gauge | Score m√©dio de churn | Business |
| `model_predictions_total` | Counter | Total de predi√ß√µes servidas | ML Metrics |
| `model_cache_hits` | Counter | Consultas em cache | ML Metrics |

### M√©tricas de Treinamento

| M√©trica | Tipo | Descri√ß√£o | Dashboard |
|---------|------|-----------|-----------|
| `model_training_duration_seconds` | Gauge | Tempo de treinamento | ML Metrics |
| `model_f2_score` | Gauge | F2-Score do modelo | ML Metrics |
| `model_auc_score` | Gauge | AUC-ROC | ML Metrics |
| `model_training_samples` | Gauge | Amostras de treino | ML Metrics |
| `model_version` | Info | Vers√£o/timestamp | ML Metrics |

---

## PASSO 1: Prepara√ß√£o do Ambiente

### 1.1 Atualizar Depend√™ncias

**Arquivo:** `requirements.txt`

**Adicionar:**
```txt
# Logging
loguru>=0.7.0

# M√©tricas e Monitoramento
prometheus-client>=0.19.0
prometheus-fastapi-instrumentator>=6.1.0
```

**Instalar:**
```bash
pip install -r requirements.txt
```

---

### 1.2 Criar Estrutura de Diret√≥rios

**Comandos:**
```bash
# Diret√≥rio de logs
mkdir -p logs

# Estrutura de monitoramento
mkdir -p monitoring/prometheus
mkdir -p monitoring/grafana/provisioning/datasources
mkdir -p monitoring/grafana/provisioning/dashboards
mkdir -p monitoring/grafana/screenshots

# Utilit√°rios
mkdir -p src/utils

# Scripts auxiliares
mkdir -p scripts

# Configura√ß√µes
mkdir -p config
```

**Estrutura Final:**
```
mlops-monitoring-prep/
‚îú‚îÄ‚îÄ logs/                              # ‚≠ê NOVO
‚îÇ   ‚îî‚îÄ‚îÄ .gitkeep
‚îú‚îÄ‚îÄ monitoring/                        # ‚≠ê NOVO
‚îÇ   ‚îú‚îÄ‚îÄ prometheus/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prometheus.yml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.prometheus
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ alert_rules.yml
‚îÇ   ‚îú‚îÄ‚îÄ grafana/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.grafana
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ grafana.ini
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ provisioning/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ datasources/
‚îÇ   ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ prometheus.yml
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ dashboards/
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ dashboards.yml
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ api-health.json
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ ml-metrics.json
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ business-churn.json
‚îÇ   ‚îÇ           ‚îî‚îÄ‚îÄ overview.json
‚îÇ   ‚îî‚îÄ‚îÄ queries_exemplos.md
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ utils/                         # ‚≠ê NOVO
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ logger.py
‚îÇ       ‚îî‚îÄ‚îÄ metrics.py
‚îú‚îÄ‚îÄ config/                            # ‚≠ê NOVO
‚îÇ   ‚îî‚îÄ‚îÄ monitoring_config.py
‚îî‚îÄ‚îÄ scripts/                           # ‚≠ê NOVO
    ‚îú‚îÄ‚îÄ start_monitoring.sh
    ‚îú‚îÄ‚îÄ test_api_load.py
    ‚îî‚îÄ‚îÄ export_metrics.py
```

---

### 1.3 Arquivos de Configura√ß√£o

**1.3.1 Criar `.gitkeep` para logs**
```bash
touch logs/.gitkeep
```

**1.3.2 Atualizar `.gitignore`**
```gitignore
# Logs
logs/*.log
logs/*.json

# Dados do Prometheus
monitoring/prometheus/data/

# Dados do Grafana
monitoring/grafana/data/

# Python
__pycache__/
*.pyc
.env
```

---

## PASSO 2: Implementa√ß√£o do Loguru

### 2.1 Criar M√≥dulo de Logging

**Arquivo:** `src/utils/logger.py`

**Funcionalidades:**
- Configura√ß√£o centralizada do Loguru
- Rota√ß√£o autom√°tica de arquivos (10 MB)
- Reten√ß√£o de 7 dias
- Formata√ß√£o customizada
- Logs estruturados (JSON opcional)
- N√≠veis por componente

**Configura√ß√µes:**
```python
# Exemplo de configura√ß√£o
logger.add(
    "logs/{time:YYYY-MM-DD}_api.log",
    rotation="10 MB",
    retention="7 days",
    level="INFO",
    format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {name}:{function}:{line} | {message}",
    serialize=False  # True para JSON
)
```

**N√≠veis de Log:**
- `TRACE`: Debug detalhado
- `DEBUG`: Informa√ß√µes de desenvolvimento
- `INFO`: Eventos normais
- `SUCCESS`: Opera√ß√µes bem-sucedidas
- `WARNING`: Alertas
- `ERROR`: Erros trat√°veis
- `CRITICAL`: Erros cr√≠ticos

---

### 2.2 Integrar nos Scripts Existentes

**Scripts a modificar:**
1. `src/treinamento.py`
2. `src/predicao.py`
3. `src/retreinamento.py`
4. `src/api_churn.py`

**Padr√£o de integra√ß√£o:**
```python
from utils.logger import logger

# Substituir print() por:
logger.info("Mensagem informativa")
logger.success("Opera√ß√£o conclu√≠da")
logger.warning("Alerta")
logger.error("Erro")
```

**Contexto adicional:**
```python
logger.info("Predi√ß√£o realizada", extra={
    "id_cliente": cliente_id,
    "risco": risco_score,
    "nivel": nivel_risco
})
```

---

### 2.3 Definir Padr√µes de Logging

**Por Componente:**

| Componente | Arquivo de Log | Eventos Principais |
|------------|----------------|-------------------|
| API | `api.log` | Requests, erros, lat√™ncia |
| Treinamento | `training.log` | Etapas, m√©tricas, dura√ß√£o |
| Predi√ß√£o | `prediction.log` | Carregamento, predi√ß√µes |
| Retreinamento | `retraining.log` | Combina√ß√£o de dados |

**Estrutura de Log (JSON):**
```json
{
  "timestamp": "2025-11-11T10:30:45.123Z",
  "level": "INFO",
  "module": "api_churn",
  "function": "obter_churn_cliente",
  "line": 85,
  "message": "Consulta de risco realizada",
  "extra": {
    "id_cliente": 12345,
    "risco": 0.75,
    "request_id": "abc-123-def"
  }
}
```

---

## PASSO 3: Implementa√ß√£o do Prometheus

### 3.1 Criar M√≥dulo de M√©tricas

**Arquivo:** `src/utils/metrics.py`

**Conte√∫do:**
- Defini√ß√£o de todas as m√©tricas
- Fun√ß√µes helpers
- Decorators para timing
- Inicializa√ß√£o das m√©tricas

**Tipos de M√©tricas:**
- **Counter**: Valores que s√≥ aumentam (ex: total de requests)
- **Gauge**: Valores que sobem/descem (ex: requests ativas)
- **Histogram**: Distribui√ß√£o de valores (ex: lat√™ncia)
- **Summary**: Estat√≠sticas (ex: percentis)
- **Info**: Metadata (ex: vers√£o do modelo)

---

### 3.2 Instrumentar API FastAPI

**Arquivo:** `src/api_churn.py`

**Adicionar:**
```python
from prometheus_fastapi_instrumentator import Instrumentator

# Ap√≥s criar app
instrumentator = Instrumentator()
instrumentator.instrument(app).expose(app)
```

**M√©tricas Autom√°ticas:**
- `http_requests_total`
- `http_request_duration_seconds`
- `http_requests_in_progress`

**Endpoint de M√©tricas:**
- URL: `http://localhost:8000/metrics`
- Formato: Prometheus text format

---

### 3.3 M√©tricas Customizadas

**Adicionar ao c√≥digo:**

```python
from utils.metrics import (
    churn_predictions_high_risk,
    churn_predictions_by_level,
    model_predictions_total
)

# Exemplo de uso
@app.get("/churn/{id_cliente}")
async def obter_churn_cliente(id_cliente: int):
    # ... c√≥digo existente ...
    
    # Incrementar m√©tricas
    model_predictions_total.inc()
    
    if risco > 0.7:
        churn_predictions_high_risk.inc()
    
    churn_predictions_by_level.labels(level=nivel_risco).set(valor)
    
    return resultado
```

---

### 3.4 Container do Prometheus

**Arquivo:** `monitoring/prometheus/prometheus.yml`

```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s
  external_labels:
    monitor: 'mlops-churn-monitor'

scrape_configs:
  - job_name: 'api-churn'
    static_configs:
      - targets: ['host.docker.internal:8000']
    metrics_path: '/metrics'
    scrape_interval: 10s
```

**Arquivo:** `monitoring/prometheus/Dockerfile.prometheus`

```dockerfile
FROM prom/prometheus:latest

COPY prometheus.yml /etc/prometheus/prometheus.yml
COPY alert_rules.yml /etc/prometheus/alert_rules.yml

EXPOSE 9090

CMD ["--config.file=/etc/prometheus/prometheus.yml", \
     "--storage.tsdb.path=/prometheus", \
     "--web.console.libraries=/usr/share/prometheus/console_libraries", \
     "--web.console.templates=/usr/share/prometheus/consoles"]
```

**Build e Run:**
```bash
# Build
docker build -f monitoring/prometheus/Dockerfile.prometheus \
  -t prometheus-mlops:latest \
  monitoring/prometheus/

# Run
docker run -d \
  --name prometheus-mlops \
  -p 9090:9090 \
  -v prometheus_data:/prometheus \
  prometheus-mlops:latest
```

**Acessar:** `http://localhost:9090`

---

## PASSO 4: Implementa√ß√£o do Grafana

### 4.1 Criar Container do Grafana

**Arquivo:** `monitoring/grafana/Dockerfile.grafana`

```dockerfile
FROM grafana/grafana:10.2.0

# Copiar configura√ß√µes
COPY grafana.ini /etc/grafana/grafana.ini

# Copiar provisioning
COPY provisioning/ /etc/grafana/provisioning/

# Configurar permiss√µes
USER root
RUN mkdir -p /var/lib/grafana && \
    chown -R grafana:grafana /var/lib/grafana

USER grafana

EXPOSE 3000
```

**Arquivo:** `monitoring/grafana/grafana.ini`

```ini
[server]
http_port = 3000

[security]
admin_user = admin
admin_password = admin

[users]
allow_sign_up = false

[analytics]
reporting_enabled = false
check_for_updates = false

[log]
mode = console
level = info
```

**Build e Run:**
```bash
# Build
docker build -f monitoring/grafana/Dockerfile.grafana \
  -t grafana-mlops:latest \
  monitoring/grafana/

# Run
docker run -d \
  --name grafana-mlops \
  -p 3000:3000 \
  -v grafana_data:/var/lib/grafana \
  grafana-mlops:latest
```

**Acessar:** `http://localhost:3000`  
**Login:** admin / admin

---

### 4.2 Configurar Datasource Prometheus

**Arquivo:** `monitoring/grafana/provisioning/datasources/prometheus.yml`

```yaml
apiVersion: 1

datasources:
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://host.docker.internal:9090
    isDefault: true
    editable: false
    jsonData:
      timeInterval: 15s
      queryTimeout: 60s
```

**Provisioning Autom√°tico:**
- Datasource criado automaticamente ao iniciar Grafana
- N√£o precisa configura√ß√£o manual

---

### 4.3 Criar Dashboards

**Arquivo:** `monitoring/grafana/provisioning/dashboards/dashboards.yml`

```yaml
apiVersion: 1

providers:
  - name: 'MLOps Dashboards'
    orgId: 1
    folder: 'MLOps Monitoring'
    type: file
    disableDeletion: false
    updateIntervalSeconds: 10
    allowUiUpdates: true
    options:
      path: /etc/grafana/provisioning/dashboards
```

#### **4.3.1 Dashboard: API Health & Performance**

**Arquivo:** `monitoring/grafana/provisioning/dashboards/api-health.json`

**Pain√©is:**
1. **Status da API** (Stat)
   - Query: `up{job="api-churn"}`
   - Cores: Verde (1) / Vermelho (0)

2. **Requisi√ß√µes/segundo** (Graph)
   - Query: `rate(api_requests_total[5m])`

3. **Lat√™ncia P95** (Gauge)
   - Query: `histogram_quantile(0.95, rate(api_request_duration_seconds_bucket[5m]))`
   - Threshold: Verde (<1s), Amarelo (1-2s), Vermelho (>2s)

4. **Taxa de Erro** (Stat + Graph)
   - Query: `(sum(rate(api_errors_total[5m])) / sum(rate(api_requests_total[5m]))) * 100`

5. **Requisi√ß√µes Ativas** (Gauge)
   - Query: `api_active_requests`

6. **Erros por C√≥digo HTTP** (Pie Chart)
   - Query: `sum(api_errors_total) by (status_code)`

#### **4.3.2 Dashboard: ML Model Metrics**

**Arquivo:** `monitoring/grafana/provisioning/dashboards/ml-metrics.json`

**Pain√©is:**
1. **F2-Score** (Gauge)
   - Query: `model_f2_score`
   - Zonas: Vermelho (<0.6), Amarelo (0.6-0.7), Verde (>0.8)

2. **AUC-ROC** (Gauge)
   - Query: `model_auc_score`

3. **Tempo de Treinamento** (Bar Chart)
   - Query: `model_training_duration_seconds`

4. **Predi√ß√µes Totais** (Stat)
   - Query: `model_predictions_total`

5. **Taxa de Predi√ß√µes/min** (Graph)
   - Query: `rate(model_predictions_total[1m])`

6. **Hist√≥rico de Vers√µes** (Table)
   - Queries: `model_f2_score`, `model_auc_score`, `model_version`

#### **4.3.3 Dashboard: Business Intelligence - Churn**

**Arquivo:** `monitoring/grafana/provisioning/dashboards/business-churn.json`

**Pain√©is:**
1. **Clientes Alto Risco** (Stat - Alerta)
   - Query: `churn_predictions_high_risk`
   - Cor: Vermelho se > 1000

2. **Distribui√ß√£o de Risco** (Pie Chart)
   - Queries:
     - `churn_predictions_by_level{level="baixo"}`
     - `churn_predictions_by_level{level="medio"}`
     - `churn_predictions_by_level{level="alto"}`

3. **Score M√©dio de Churn** (Gauge)
   - Query: `churn_prediction_score_avg`

4. **Evolu√ß√£o por N√≠vel** (Stacked Area)
   - Query: `churn_predictions_by_level`

5. **Taxa de Consultas** (Graph)
   - Query: `rate(api_requests_total{endpoint="/churn"}[5m])`

#### **4.3.4 Dashboard: System Overview**

**Arquivo:** `monitoring/grafana/provisioning/dashboards/overview.json`

**Pain√©is:**
1. **Resumo de Status** (Stat Grid)
   - API Status, F2-Score, Taxa Erro, Uptime

2. **Atividade Geral** (Graph)
   - Requests, Predi√ß√µes, Erros

3. **M√©tricas Principais** (Table)
   - Todas as m√©tricas importantes

---

### 4.4 Configurar Alertas

**Alertas no Grafana:**

| Nome | Condi√ß√£o | Severidade | Notifica√ß√£o |
|------|----------|------------|-------------|
| API Down | `up{job="api"} == 0` por 1min | Critical | Email/Slack |
| Alta Lat√™ncia | P95 > 2s por 5min | Warning | Email |
| Taxa de Erro Alta | Erro > 5% por 5min | Warning | Email |
| F2-Score Baixo | F2 < 0.7 | Warning | Email |
| Sem Predi√ß√µes | Nenhuma em 1h | Warning | Email |
| Spike de Churn | Alto risco aumentou 20% | Critical | Email/Slack |

**Configura√ß√£o de Notification Channel (exemplo):**
```json
{
  "name": "Email MLOps Team",
  "type": "email",
  "isDefault": true,
  "settings": {
    "addresses": "mlops-team@example.com"
  }
}
```

---

## PASSO 5: M√©tricas de Machine Learning

### 5.1 Instrumentar Treinamento

**Arquivo:** `src/treinamento.py`

**Adicionar:**
```python
from utils.logger import logger
from utils.metrics import (
    model_training_duration_seconds,
    model_f2_score,
    model_auc_score,
    model_training_samples
)
import time

# In√≠cio do treino
logger.info("Iniciando treinamento do modelo")
start_time = time.time()

# ... c√≥digo de treinamento existente ...

# Ao final
duration = time.time() - start_time
model_training_duration_seconds.set(duration)
model_f2_score.set(metricas['f2_score'])
model_auc_score.set(metricas['auc'])
model_training_samples.set(len(X_train) + len(X_test))

logger.success(f"Modelo treinado em {duration:.2f}s", extra={
    "f2_score": metricas['f2_score'],
    "auc": metricas['auc'],
    "samples": len(X_train) + len(X_test)
})
```

**Logs por Etapa:**
```python
logger.info("Etapa 1: Carregamento de dados")
logger.info("Etapa 2: Separa√ß√£o treino/teste")
logger.debug(f"X_train shape: {X_train.shape}")
logger.info("Etapa 3: Imputa√ß√£o de valores ausentes")
logger.info("Etapa 4: Transforma√ß√µes")
logger.info("Etapa 5: SMOTE")
logger.info("Etapa 6: Treinamento do modelo")
logger.success("Treinamento conclu√≠do")
```

---

### 5.2 Instrumentar Predi√ß√£o

**Arquivo:** `src/predicao.py`

**Adicionar:**
```python
from utils.logger import logger
from utils.metrics import (
    churn_predictions_high_risk,
    churn_predictions_by_level,
    churn_prediction_score_avg
)

logger.info("Carregando modelo treinado")
pipeline = joblib.load("models/pipeline_modelo_treinado.joblib")

logger.info("Fazendo predi√ß√µes")
preds = pipeline.predict_proba(X)[:,1]

# Calcular m√©tricas de distribui√ß√£o
high_risk_count = (preds > 0.7).sum()
churn_predictions_high_risk.set(high_risk_count)

avg_score = preds.mean()
churn_prediction_score_avg.set(avg_score)

# Por n√≠vel
baixo = (preds < 0.5).sum()
medio = ((preds >= 0.5) & (preds < 0.7)).sum()
alto = (preds >= 0.7).sum()

churn_predictions_by_level.labels(level="baixo").set(baixo)
churn_predictions_by_level.labels(level="medio").set(medio)
churn_predictions_by_level.labels(level="alto").set(alto)

logger.success(f"Predi√ß√µes conclu√≠das: {len(preds)} clientes", extra={
    "alto_risco": int(high_risk_count),
    "score_medio": float(avg_score)
})
```

---

### 5.3 M√©tricas de Neg√≥cio

**Contexto Adicional nos Logs:**

```python
# API - Log de cada requisi√ß√£o
logger.info("Consulta de churn realizada", extra={
    "id_cliente": id_cliente,
    "risco": risco,
    "nivel": nivel_risco,
    "endpoint": "/churn/{id}",
    "method": "GET",
    "status_code": 200,
    "response_time_ms": tempo_resposta
})

# An√°lise agregada
logger.info("An√°lise de risco conclu√≠da", extra={
    "total_clientes": total,
    "alto_risco": alto_risco_count,
    "percentual_alto_risco": (alto_risco_count/total)*100
})
```

---

## PASSO 6: Integra√ß√£o e Testes

### 6.1 Scripts de Inicializa√ß√£o

**Arquivo:** `scripts/start_monitoring.sh`

```bash
#!/bin/bash

echo "=== Iniciando Stack de Monitoramento MLOps ==="

# Criar networks se n√£o existirem
docker network create mlops-network 2>/dev/null || true

echo ""
echo "1. Iniciando Prometheus..."
docker run -d \
  --name prometheus-mlops \
  --network mlops-network \
  -p 9090:9090 \
  -v prometheus_data:/prometheus \
  prometheus-mlops:latest

echo "‚úì Prometheus rodando em http://localhost:9090"

echo ""
echo "2. Iniciando Grafana..."
docker run -d \
  --name grafana-mlops \
  --network mlops-network \
  -p 3000:3000 \
  -v grafana_data:/var/lib/grafana \
  grafana-mlops:latest

echo "‚úì Grafana rodando em http://localhost:3000"
echo "  Login: admin / admin"

echo ""
echo "3. Aguardando servi√ßos iniciarem..."
sleep 10

echo ""
echo "=== Status dos Servi√ßos ==="
docker ps | grep mlops

echo ""
echo "=== Monitoramento Pronto! ==="
echo "Prometheus: http://localhost:9090"
echo "Grafana:    http://localhost:3000"
echo ""
echo "Pr√≥ximo passo: Iniciar a API FastAPI"
echo "  uvicorn src.api_churn:app --reload"
```

**Tornar execut√°vel:**
```bash
chmod +x scripts/start_monitoring.sh
```

---

### 6.2 Testes de Carga

**Arquivo:** `scripts/test_api_load.py`

```python
"""
Script para gerar carga na API e testar monitoramento
"""
import requests
import time
import random
from concurrent.futures import ThreadPoolExecutor

API_URL = "http://localhost:8000"

def fazer_requisicao_churn(id_cliente):
    """Faz uma requisi√ß√£o para o endpoint de churn"""
    try:
        response = requests.get(f"{API_URL}/churn/{id_cliente}")
        return response.status_code
    except Exception as e:
        return None

def teste_carga(num_requests=100, workers=10):
    """Executa teste de carga"""
    print(f"Iniciando teste de carga: {num_requests} requests com {workers} workers")
    
    # IDs aleat√≥rios (assumindo que existem entre 1-10000)
    ids = [random.randint(1, 10000) for _ in range(num_requests)]
    
    start_time = time.time()
    
    with ThreadPoolExecutor(max_workers=workers) as executor:
        results = list(executor.map(fazer_requisicao_churn, ids))
    
    duration = time.time() - start_time
    
    # Estat√≠sticas
    success = sum(1 for r in results if r == 200)
    not_found = sum(1 for r in results if r == 404)
    errors = sum(1 for r in results if r not in [200, 404])
    
    print(f"\n=== Resultados ===")
    print(f"Dura√ß√£o: {duration:.2f}s")
    print(f"Requests/s: {num_requests/duration:.2f}")
    print(f"Sucesso (200): {success}")
    print(f"N√£o encontrado (404): {not_found}")
    print(f"Erros: {errors}")

if __name__ == "__main__":
    print("Aguardando 5s para voc√™ abrir o Grafana...")
    time.sleep(5)
    
    print("\n=== Teste 1: Carga Leve ===")
    teste_carga(num_requests=50, workers=5)
    time.sleep(2)
    
    print("\n=== Teste 2: Carga M√©dia ===")
    teste_carga(num_requests=200, workers=10)
    time.sleep(2)
    
    print("\n=== Teste 3: Carga Pesada ===")
    teste_carga(num_requests=500, workers=20)
    
    print("\n‚úì Testes conclu√≠dos! Verifique os dashboards do Grafana.")
```

**Executar:**
```bash
python scripts/test_api_load.py
```

---

### 6.3 Documenta√ß√£o

**Arquivo:** `tutorial/MONITORING.md`

**Conte√∫do:**
- Vis√£o geral do monitoramento
- Como executar cada componente
- Interpreta√ß√£o das m√©tricas
- Troubleshooting

**Arquivo:** `tutorial/PROMETHEUS.md`

**Conte√∫do:**
- Introdu√ß√£o ao Prometheus
- PromQL b√°sico
- Queries √∫teis
- Exemplos pr√°ticos

**Arquivo:** `tutorial/GRAFANA.md`

**Conte√∫do:**
- Introdu√ß√£o ao Grafana
- Navega√ß√£o nos dashboards
- Como criar pain√©is customizados
- Configura√ß√£o de alertas
- Exportar/Importar dashboards

**Arquivo:** `monitoring/queries_exemplos.md`

**Conte√∫do:**
- Queries PromQL organizadas por categoria
- Exemplos de an√°lises
- Queries avan√ßadas

---

### 6.4 Exemplos Pr√°ticos

**Queries PromQL √öteis:**

```promql
# Taxa de requisi√ß√µes por segundo
rate(api_requests_total[5m])

# Lat√™ncia P95
histogram_quantile(0.95, rate(api_request_duration_seconds_bucket[5m]))

# Taxa de erro percentual
(sum(rate(api_errors_total[5m])) / sum(rate(api_requests_total[5m]))) * 100

# Clientes em alto risco
churn_predictions_high_risk

# Distribui√ß√£o de risco
sum(churn_predictions_by_level) by (level)

# Evolu√ß√£o do F2-Score
model_f2_score

# Compara√ß√£o com vers√£o anterior (1 dia atr√°s)
model_f2_score - model_f2_score offset 1d
```

**Cen√°rios de Debugging:**

1. **Lat√™ncia alta detectada**
   - Abrir dashboard API Health
   - Verificar painel de lat√™ncia
   - Correlacionar com logs: `tail -f logs/api.log | grep "duration_ms"`
   - Identificar endpoint lento

2. **Taxa de erro aumentou**
   - Verificar painel de erros por c√≥digo
   - Buscar em logs: `grep ERROR logs/api.log`
   - Analisar stack traces

3. **F2-Score caiu**
   - Abrir dashboard ML Metrics
   - Verificar hist√≥rico
   - Comparar com vers√£o anterior
   - Investigar data drift

---

## üìö RECURSOS ADICIONAIS

### Queries PromQL por Categoria

**Performance:**
```promql
# Requests por endpoint
sum(rate(api_requests_total[5m])) by (endpoint)

# Lat√™ncia m√©dia
avg(rate(api_request_duration_seconds_sum[5m]) / 
    rate(api_request_duration_seconds_count[5m]))

# P99 de lat√™ncia
histogram_quantile(0.99, 
  sum(rate(api_request_duration_seconds_bucket[5m])) by (le))
```

**Erros:**
```promql
# Taxa de erro
rate(api_errors_total[5m]) / rate(api_requests_total[5m])

# Erros por tipo
sum(rate(api_errors_total[5m])) by (status_code)
```

**ML Metrics:**
```promql
# Evolu√ß√£o do F2-Score
model_f2_score

# Drift do score m√©dio
churn_prediction_score_avg - churn_prediction_score_avg offset 1h

# Taxa de predi√ß√µes de alto risco
(churn_predictions_by_level{level="alto"} / 
 sum(churn_predictions_by_level)) * 100
```

---

## üéØ OBJETIVOS PEDAG√ìGICOS

### Por Fase

| Fase | Conceitos Ensinados | Habilidades Desenvolvidas |
|------|---------------------|---------------------------|
| **Passo 1** | Gest√£o de depend√™ncias, estrutura de projetos | Organiza√ß√£o, planejamento |
| **Passo 2** | Logging estruturado, debugging | Rastreabilidade, troubleshooting |
| **Passo 3** | M√©tricas de aplica√ß√£o, observabilidade | Monitoramento, performance |
| **Passo 4** | Visualiza√ß√£o de dados, dashboards | An√°lise, comunica√ß√£o de dados |
| **Passo 5** | MLOps, m√©tricas de modelo | ML monitoring, data drift |
| **Passo 6** | Integra√ß√£o, testes, documenta√ß√£o | DevOps, SRE, boas pr√°ticas |

### Compet√™ncias Desenvolvidas

‚úÖ **T√©cnicas:**
- Configura√ß√£o de ferramentas de monitoramento
- Escrita de queries PromQL
- Cria√ß√£o de dashboards visuais
- An√°lise de m√©tricas e logs
- Debugging de aplica√ß√µes

‚úÖ **Conceituais:**
- Observabilidade vs Monitoramento
- Cultura DevOps/SRE
- MLOps e ML Monitoring
- Data Drift Detection
- Incident Response

‚úÖ **Soft Skills:**
- Comunica√ß√£o t√©cnica
- Documenta√ß√£o clara
- Trabalho em equipe
- Tomada de decis√£o baseada em dados

---

## ‚è±Ô∏è CRONOGRAMA SUGERIDO

### Distribui√ß√£o em 6 Semanas (Aulas Semanais)

| Semana | Passo | Atividades | Entreg√°vel |
|--------|-------|------------|------------|
| **1** | Passo 1 | Setup do ambiente, estrutura de pastas | Ambiente configurado |
| **2** | Passo 2 | Implementar Loguru, integrar scripts | Logs funcionando |
| **3** | Passo 3 | Prometheus client, m√©tricas b√°sicas | /metrics endpoint |
| **4** | Passo 4 | Grafana, datasource, dashboards | Dashboards visuais |
| **5** | Passo 5 | M√©tricas ML, instrumenta√ß√£o completa | M√©tricas de modelo |
| **6** | Passo 6 | Testes, documenta√ß√£o, apresenta√ß√£o | Projeto completo |

### Por Aula (Exemplo de 2h/aula)

**Aula 1 - Prepara√ß√£o:**
- 30min: Apresenta√ß√£o do projeto e ferramentas
- 30min: Instala√ß√£o de depend√™ncias
- 30min: Cria√ß√£o da estrutura de pastas
- 30min: Configura√ß√£o inicial

**Aula 2 - Loguru:**
- 30min: Teoria de logging estruturado
- 45min: Implementa√ß√£o do m√≥dulo logger
- 45min: Integra√ß√£o nos scripts existentes

**Aula 3 - Prometheus:**
- 30min: Teoria de m√©tricas
- 30min: Implementa√ß√£o do m√≥dulo metrics
- 30min: Instrumenta√ß√£o da API
- 30min: Container do Prometheus

**Aula 4 - Grafana:**
- 30min: Introdu√ß√£o ao Grafana
- 45min: Configura√ß√£o de datasource
- 45min: Cria√ß√£o de dashboards

**Aula 5 - ML Metrics:**
- 30min: MLOps e monitoramento de modelos
- 60min: Instrumenta√ß√£o de treinamento e predi√ß√£o
- 30min: An√°lise de m√©tricas de neg√≥cio

**Aula 6 - Integra√ß√£o:**
- 30min: Testes de carga
- 30min: Debugging e troubleshooting
- 30min: Documenta√ß√£o
- 30min: Apresenta√ß√£o de resultados

---

## ‚úÖ CHECKLIST DE IMPLEMENTA√á√ÉO

### Passo 1: Prepara√ß√£o
- [ ] Atualizar `requirements.txt`
- [ ] Instalar depend√™ncias
- [ ] Criar estrutura de pastas
- [ ] Criar `.gitkeep` em logs/
- [ ] Atualizar `.gitignore`

### Passo 2: Loguru
- [ ] Criar `src/utils/__init__.py`
- [ ] Criar `src/utils/logger.py`
- [ ] Modificar `src/treinamento.py`
- [ ] Modificar `src/predicao.py`
- [ ] Modificar `src/retreinamento.py`
- [ ] Modificar `src/api_churn.py`
- [ ] Testar logs em todos os scripts

### Passo 3: Prometheus
- [ ] Criar `src/utils/metrics.py`
- [ ] Instrumentar API com Instrumentator
- [ ] Adicionar m√©tricas customizadas
- [ ] Criar `monitoring/prometheus/prometheus.yml`
- [ ] Criar `monitoring/prometheus/Dockerfile.prometheus`
- [ ] Build da imagem Prometheus
- [ ] Executar container Prometheus
- [ ] Testar endpoint `/metrics`

### Passo 4: Grafana
- [ ] Criar `monitoring/grafana/grafana.ini`
- [ ] Criar `monitoring/grafana/Dockerfile.grafana`
- [ ] Criar `provisioning/datasources/prometheus.yml`
- [ ] Criar `provisioning/dashboards/dashboards.yml`
- [ ] Criar dashboard `api-health.json`
- [ ] Criar dashboard `ml-metrics.json`
- [ ] Criar dashboard `business-churn.json`
- [ ] Criar dashboard `overview.json`
- [ ] Build da imagem Grafana
- [ ] Executar container Grafana
- [ ] Testar acesso ao Grafana
- [ ] Verificar datasource conectado
- [ ] Verificar dashboards carregados
- [ ] Configurar alertas

### Passo 5: ML Metrics
- [ ] Adicionar m√©tricas em `treinamento.py`
- [ ] Adicionar m√©tricas em `predicao.py`
- [ ] Exportar m√©tricas de treinamento
- [ ] Calcular m√©tricas de distribui√ß√£o
- [ ] Testar m√©tricas no Prometheus

### Passo 6: Integra√ß√£o
- [ ] Criar `scripts/start_monitoring.sh`
- [ ] Criar `scripts/test_api_load.py`
- [ ] Criar `scripts/export_metrics.py`
- [ ] Criar `tutorial/MONITORING.md`
- [ ] Criar `tutorial/PROMETHEUS.md`
- [ ] Criar `tutorial/GRAFANA.md`
- [ ] Criar `monitoring/queries_exemplos.md`
- [ ] Executar testes de carga
- [ ] Validar todos os componentes
- [ ] Tirar screenshots dos dashboards
- [ ] Revisar documenta√ß√£o

---

## üöÄ COMANDOS R√ÅPIDOS

### Iniciar Stack de Monitoramento

```bash
# Executar script de inicializa√ß√£o
./scripts/start_monitoring.sh

# OU manualmente:

# 1. Prometheus
docker run -d --name prometheus-mlops -p 9090:9090 prometheus-mlops:latest

# 2. Grafana
docker run -d --name grafana-mlops -p 3000:3000 grafana-mlops:latest

# 3. API
uvicorn src.api_churn:app --reload --port 8000
```

### Verificar Status

```bash
# Ver containers rodando
docker ps | grep mlops

# Logs do Prometheus
docker logs prometheus-mlops

# Logs do Grafana
docker logs grafana-mlops

# Logs da API
tail -f logs/api.log
```

### Acessar Servi√ßos

```bash
# Abrir Prometheus
"$BROWSER" http://localhost:9090

# Abrir Grafana
"$BROWSER" http://localhost:3000

# Abrir API Docs
"$BROWSER" http://localhost:8000/docs

# Endpoint de m√©tricas
curl http://localhost:8000/metrics
```

### Parar e Limpar

```bash
# Parar containers
docker stop prometheus-mlops grafana-mlops

# Remover containers
docker rm prometheus-mlops grafana-mlops

# Limpar volumes (CUIDADO: perde dados)
docker volume rm prometheus_data grafana_data
```

---

## üìñ REFER√äNCIAS

### Documenta√ß√£o Oficial
- **Loguru:** https://loguru.readthedocs.io/
- **Prometheus:** https://prometheus.io/docs/
- **Grafana:** https://grafana.com/docs/grafana/latest/
- **FastAPI:** https://fastapi.tiangolo.com/

### Tutoriais Recomendados
- Prometheus Basics: https://prometheus.io/docs/introduction/first_steps/
- PromQL Guide: https://prometheus.io/docs/prometheus/latest/querying/basics/
- Grafana Fundamentals: https://grafana.com/tutorials/grafana-fundamentals/
- MLOps Best Practices: https://ml-ops.org/

### Dashboards de Exemplo
- Grafana Dashboard Library: https://grafana.com/grafana/dashboards/
- FastAPI Dashboard: ID 16110
- Node Exporter: ID 1860

---

## üí° DICAS E BOAS PR√ÅTICAS

### Logging
‚úÖ Use n√≠veis apropriados (INFO, WARNING, ERROR)
‚úÖ Adicione contexto relevante nos logs
‚úÖ Evite logar informa√ß√µes sens√≠veis
‚úÖ Use logs estruturados (JSON) para an√°lise

### M√©tricas
‚úÖ Nomeie m√©tricas de forma consistente
‚úÖ Use labels para dimensionalidade
‚úÖ Evite cardinalidade alta em labels
‚úÖ Documente o significado de cada m√©trica

### Dashboards
‚úÖ Organize pain√©is logicamente
‚úÖ Use cores significativas (verde=ok, vermelho=erro)
‚úÖ Adicione descri√ß√µes nos pain√©is
‚úÖ Configure time ranges apropriados

### Alertas
‚úÖ Defina thresholds realistas
‚úÖ Evite alertas excessivos (alert fatigue)
‚úÖ Teste alertas regularmente
‚úÖ Documente a√ß√µes de resposta

---

## üéì EXERC√çCIOS PROPOSTOS PARA ALUNOS

### Exerc√≠cio 1: Criar M√©trica Customizada
**Objetivo:** Adicionar uma m√©trica que conta quantos clientes de cada pa√≠s foram consultados

**Tarefas:**
1. Definir m√©trica em `metrics.py`
2. Instrumentar endpoint da API
3. Criar painel no Grafana
4. Analisar distribui√ß√£o geogr√°fica

### Exerc√≠cio 2: Dashboard Personalizado
**Objetivo:** Criar dashboard comparando performance de diferentes vers√µes do modelo

**Tarefas:**
1. Exportar m√©tricas de m√∫ltiplos treinamentos
2. Criar dashboard com pain√©is comparativos
3. Usar vari√°veis para filtrar por vers√£o
4. Adicionar anota√ß√µes de deploys

### Exerc√≠cio 3: Alerta de Data Drift
**Objetivo:** Configurar alerta quando score m√©dio aumentar significativamente

**Tarefas:**
1. Definir query PromQL para detectar drift
2. Configurar alerta no Grafana
3. Testar com dados simulados
4. Documentar plano de a√ß√£o

### Exerc√≠cio 4: An√°lise de Logs
**Objetivo:** Encontrar padr√µes em logs usando grep/awk/jq

**Tarefas:**
1. Buscar todos os erros na √∫ltima hora
2. Contar requisi√ß√µes por endpoint
3. Calcular tempo m√©dio de resposta
4. Identificar clientes mais consultados

---

## üìä M√âTRICAS DE SUCESSO DO PROJETO

### Crit√©rios de Avalia√ß√£o

| Crit√©rio | Peso | Descri√ß√£o |
|----------|------|-----------|
| **Implementa√ß√£o T√©cnica** | 40% | Todos os componentes funcionando |
| **Dashboards** | 20% | Visualiza√ß√µes claras e √∫teis |
| **Documenta√ß√£o** | 20% | Tutoriais e README completos |
| **Testes** | 10% | Testes de carga executados |
| **Apresenta√ß√£o** | 10% | Demo e explica√ß√£o do projeto |

### Indicadores de Sucesso

‚úÖ Loguru capturando logs de todos os scripts
‚úÖ Prometheus coletando m√©tricas da API
‚úÖ Grafana exibindo 4 dashboards funcionais
‚úÖ M√©tricas de ML sendo registradas
‚úÖ Alertas configurados e testados
‚úÖ Documenta√ß√£o completa
‚úÖ Testes de carga validando performance

---

## üîÑ PR√ìXIMAS EVOLU√á√ïES (Opcional)

### Para Alunos Avan√ßados

**N√≠vel 1 - Intermedi√°rio:**
- [ ] Adicionar Loki para centraliza√ß√£o de logs
- [ ] Criar mais dashboards espec√≠ficos
- [ ] Implementar notifica√ß√µes via Slack
- [ ] Adicionar m√©tricas de infraestrutura (CPU, mem√≥ria)

**N√≠vel 2 - Avan√ßado:**
- [ ] Implementar Jaeger para distributed tracing
- [ ] Adicionar Alertmanager
- [ ] Criar pipeline de CI/CD com valida√ß√£o de m√©tricas
- [ ] Implementar feature store com monitoramento

**N√≠vel 3 - Expert:**
- [ ] Data drift detection com Evidently
- [ ] Model explainability com SHAP
- [ ] A/B testing de modelos com m√©tricas
- [ ] Anomaly detection em m√©tricas

---

## ‚ú® CONCLUS√ÉO

Este planejamento fornece um guia completo para implementar observabilidade em um projeto MLOps acad√™mico. Seguindo os 6 passos, os alunos desenvolver√£o compet√™ncias pr√°ticas em:

- **Logging estruturado** com Loguru
- **M√©tricas de aplica√ß√£o** com Prometheus
- **Visualiza√ß√£o de dados** com Grafana
- **MLOps** e monitoramento de modelos
- **DevOps/SRE** e cultura de observabilidade

**Tempo estimado:** 6 semanas  
**N√≠vel:** Intermedi√°rio  
**Pr√©-requisitos:** Python, Docker, FastAPI b√°sico

---

**√öltima atualiza√ß√£o:** Novembro 2025  
**Vers√£o:** 1.0  
**Autor:** Projeto MLOps Monitoring Prep
