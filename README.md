# MLOps - Modelo de PrediÃ§Ã£o de EvasÃ£o de Clientes (Churn) ï¿½

[![Python](https://img.shields.io/badge/Python-3.x-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104-green.svg)](https://fastapi.tiangolo.com/)
[![Prometheus](https://img.shields.io/badge/Prometheus-2.47-orange.svg)](https://prometheus.io/)
[![Grafana](https://img.shields.io/badge/Grafana-10.2-red.svg)](https://grafana.com/)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://www.docker.com/)

**Sistema completo de MLOps** com monitoramento em tempo real usando **Prometheus** e **Grafana**!

## ğŸ“‹ Ãndice

- [ğŸ¯ Sobre o Projeto](#-sobre-o-projeto)
- [âœ¨ Recursos de Monitoramento](#-recursos-de-monitoramento)
- [ğŸ“ Estrutura do Projeto](#-estrutura-do-projeto)
- [ğŸš€ Quick Start](#-quick-start)
- [ğŸ“Š Monitoramento](#-monitoramento)
- [ğŸŒ API de PrediÃ§Ã£o](#-api-de-prediÃ§Ã£o)
- [ğŸ”§ Tecnologias](#-tecnologias)
- [ğŸ“š Tutoriais](#-tutoriais)
- [ğŸ³ Docker](#-docker)
- [ğŸ“ˆ Pipeline de ML](#-pipeline-de-ml)
- [ğŸ¤ Contribuindo](#-contribuindo)

## ğŸ¯ Sobre o Projeto

Este projeto implementa um **pipeline completo de MLOps** para prediÃ§Ã£o de evasÃ£o de clientes bancÃ¡rios (churn). O sistema utiliza:

- ğŸ¤– **Random Forest** com balanceamento SMOTE
- ğŸ“¡ **API REST** com FastAPI
- ğŸ“Š **Monitoramento** com Prometheus + Grafana
- ğŸ“ **Logging estruturado** com Loguru
- ğŸ³ **ContainerizaÃ§Ã£o** com Docker

**Ideal para aprendizado de MLOps em ambiente acadÃªmico!**

## âœ¨ Recursos de Monitoramento

### ğŸ“Š Stack de Observabilidade Completa

- **ğŸ“ Loguru**: Logging estruturado com rotaÃ§Ã£o automÃ¡tica
- **ğŸ“ˆ Prometheus**: Coleta e armazenamento de mÃ©tricas
- **ğŸ“Š Grafana**: 4 dashboards profissionais prÃ©-configurados
- **ğŸ”” Alertas**: 5 alertas automÃ¡ticos para problemas crÃ­ticos

### ğŸ“Š Dashboards DisponÃ­veis

| Dashboard | DescriÃ§Ã£o | UsuÃ¡rio |
|-----------|-----------|---------|
| ğŸ¯ **System Overview** | VisÃ£o executiva geral | CEO/Gestores |
| ğŸš€ **API Health** | Performance da API | DevOps/SRE |
| ğŸ¤– **ML Metrics** | Qualidade do modelo | Data Scientists |
| ğŸ’¼ **Business Churn** | KPIs de negÃ³cio | Analistas |

### ğŸ“ MÃ©tricas Coletadas

**Infraestrutura (17 mÃ©tricas)**
- Taxa de requisiÃ§Ãµes, latÃªncia, erros
- Uptime, requests ativas
- Tempo de resposta P50/P95/P99

**Machine Learning (6 mÃ©tricas)**
- F2-Score, AUC-ROC, Precision, Recall
- DuraÃ§Ã£o de treinamento
- Total de amostras

**NegÃ³cio (5 mÃ©tricas)**
- Clientes em alto/mÃ©dio/baixo risco
- Score mÃ©dio de churn
- DistribuiÃ§Ã£o de prediÃ§Ãµes

## ğŸš€ Quick Start

### OpÃ§Ã£o 1: Iniciar Tudo com 1 Comando ğŸ¯

```bash
# Clonar repositÃ³rio
git clone https://github.com/seu-usuario/mlops-monitoring-prep.git
cd mlops-monitoring-prep

# Iniciar stack completa (API + Prometheus + Grafana)
./scripts/start_monitoring.sh
```

**Acessar:**
- ğŸŒ **API**: http://localhost:8000/docs
- ğŸ“Š **Prometheus**: http://localhost:9090
- ğŸ“ˆ **Grafana**: http://localhost:3000 (admin/admin)

### OpÃ§Ã£o 2: Passo a Passo Manual

```bash
# 1. Criar ambiente virtual
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# 2. Instalar dependÃªncias
pip install -r requirements.txt

# 3. Treinar modelo
python src/treinamento.py

# 4. Fazer prediÃ§Ãµes
python src/predicao.py

# 5. Subir API
uvicorn src.api_churn:app --host 0.0.0.0 --port 8000

# 6. Testar com carga
python scripts/test_api_load.py
```

## ğŸ“Š Monitoramento

### Arquitetura de Monitoramento

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Treinamento â”‚â”€â”€â”
â”‚  PrediÃ§Ã£o   â”‚  â”‚ Loguru
â”‚ Retreinamentoâ”‚  â”‚ (logs/)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API Churn  â”‚â”€â†’â”‚Prometheusâ”‚â†â”€â”‚ Grafana â”‚
â”‚   :8000     â”‚  â”‚  :9090   â”‚  â”‚  :3000  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    /metrics       scrape        dashboards
```

### Ver Dashboards

1. **Iniciar stack**: `./scripts/start_monitoring.sh`
2. **Acessar Grafana**: http://localhost:3000
3. **Login**: admin / admin
4. **Selecionar** dashboard desejado
5. **Gerar mÃ©tricas**: `python scripts/test_api_load.py`

### Consultar MÃ©tricas

```bash
# Diretamente no Prometheus
curl http://localhost:9090/api/v1/query?query=model_f2_score

# Endpoint de mÃ©tricas da API
curl http://localhost:8000/metrics

# Exportar para arquivo
python scripts/export_metrics.py
```

### Alertas Configurados

| Alerta | CondiÃ§Ã£o | Severidade |
|--------|----------|------------|
| ğŸ”´ **APIDown** | API offline > 1min | Critical |
| ğŸŸ  **HighErrorRate** | Erros > 5% | Warning |
| ğŸŸ¡ **HighLatency** | P95 > 500ms | Warning |
| ğŸŸ  **ModelDegraded** | F2-Score < 0.7 | Warning |
| ğŸŸ¡ **HighChurnRisk** | Alto risco > 1000 | Info |

### Parar Monitoramento

```bash
# Parar todos containers
./scripts/stop_monitoring.sh

# Parar e limpar tudo
./scripts/stop_monitoring.sh --clean
```

## ğŸ“ Estrutura do Projeto

```
mlops-docker-template/
â”œâ”€â”€ data/                           # Dados do projeto
â”‚   â”œâ”€â”€ raw/                        # Dados brutos
â”‚   â”‚   â”œâ”€â”€ dados_treino.csv        # Dataset inicial de treinamento
â”‚   â”‚   â”œâ”€â”€ dados_novos_1.csv       # Novos dados para prediÃ§Ã£o/retreino
â”‚   â”‚   â””â”€â”€ dados_novos_2.csv       # Novos dados para prediÃ§Ã£o/retreino
â”‚   â””â”€â”€ docs/                       # DocumentaÃ§Ã£o dos dados
â”‚       â””â”€â”€ bank_churn_dict.csv     # DicionÃ¡rio de dados
â”‚
â”œâ”€â”€ src/                            # CÃ³digo fonte
â”‚   â”œâ”€â”€ treinamento.py              # Script de treinamento do modelo
â”‚   â”œâ”€â”€ predicao.py                 # Script de prediÃ§Ã£o
â”‚   â””â”€â”€ retreinamento.py            # Script auxiliar de retreinamento
â”‚
â”œâ”€â”€ models/                         # Modelos treinados
â”‚   â””â”€â”€ pipeline_modelo_treinado.joblib
â”‚
â”œâ”€â”€ outputs/                        # Resultados e mÃ©tricas
â”‚   â”œâ”€â”€ metricas_desempenho_evasao.csv
â”‚   â””â”€â”€ predicoes.csv
â”‚
â”œâ”€â”€ src/                            # CÃ³digo fonte
â”‚   â”œâ”€â”€ api_churn.py                # API FastAPI para consulta de prediÃ§Ãµes
â”‚   â”œâ”€â”€ treinamento.py              # Script de treinamento do modelo
â”‚   â”œâ”€â”€ predicao.py                 # Script de prediÃ§Ã£o
â”‚   â””â”€â”€ retreinamento.py            # Script auxiliar de retreinamento
â”‚
â”œâ”€â”€ Dockerfile.api                  # Dockerfile para a API
â”œâ”€â”€ docker-compose.yml              # ConfiguraÃ§Ã£o Docker Compose
â”œâ”€â”€ docker-api.sh                   # Script auxiliar para gerenciar Docker
â”œâ”€â”€ .dockerignore                   # Arquivos ignorados no build Docker
â”œâ”€â”€ .gitignore                      # Arquivos ignorados pelo Git
â”œâ”€â”€ requirements.txt                # DependÃªncias do projeto
â”œâ”€â”€ API_CHURN_README.md             # DocumentaÃ§Ã£o da API
â”œâ”€â”€ DOCKER_API.md                   # DocumentaÃ§Ã£o Docker
â”œâ”€â”€ README.md                       # Este arquivo
â””â”€â”€ README.txt                      # DocumentaÃ§Ã£o original
```

## ğŸŒ API de PrediÃ§Ã£o de Churn

Este projeto inclui uma API REST desenvolvida com FastAPI para consultar prediÃ§Ãµes de risco de churn.

**DocumentaÃ§Ã£o completa:** [API_CHURN_README.md](API_CHURN_README.md)

### Iniciar a API localmente

```bash
uvicorn src.api_churn:app --host 0.0.0.0 --port 8000 --reload
```

### Endpoints principais

- `GET /` - InformaÃ§Ãµes da API
- `GET /health` - Status e health check
- `GET /churn/{id_cliente}` - Consultar risco de churn por ID
- `GET /churn/todas/predicoes` - Listar todas as prediÃ§Ãµes
- `GET /docs` - DocumentaÃ§Ã£o interativa (Swagger)


## ï¿½ Tutoriais

### Guias Completos para Alunos

| Tutorial | DescriÃ§Ã£o | Tempo estimado |
|----------|-----------|----------------|
| ğŸ“Š [**PROMETHEUS.md**](tutorial/PROMETHEUS.md) | Como usar Prometheus, PromQL, alertas | 45 min |
| ğŸ“ˆ [**GRAFANA.md**](tutorial/GRAFANA.md) | Dashboards, painÃ©is, visualizaÃ§Ãµes | 60 min |
| ğŸ³ [**DOCKER_API.md**](tutorial/DOCKER_API.md) | Containers, builds, deploy | 30 min |
| ğŸŒ [**API_CHURN_README.md**](tutorial/API_CHURN_README.md) | Endpoints, FastAPI, testes | 30 min |

### Planejamento de ImplementaÃ§Ã£o

ğŸ“‹ **[PLANEJAMENTO_MONITORAMENTO.md](monitoring/PLANEJAMENTO_MONITORAMENTO.md)**
- VisÃ£o geral de 6 passos de implementaÃ§Ã£o
- MÃ©tricas definidas e categorizadas
- Arquitetura de monitoramento
- Timeline de desenvolvimento

### ExercÃ­cios PrÃ¡ticos

Todos os tutoriais incluem:
- âœ… Conceitos teÃ³ricos explicados
- âœ… Exemplos prÃ¡ticos passo a passo
- âœ… ExercÃ­cios com soluÃ§Ãµes
- âœ… Troubleshooting de problemas comuns

## ğŸ”§ Tecnologias

### Machine Learning
- **Python 3.x**
- **pandas** - ManipulaÃ§Ã£o de dados
- **numpy** - OperaÃ§Ãµes numÃ©ricas
- **scikit-learn** - Algoritmos de ML e prÃ©-processamento
- **imbalanced-learn** - Tratamento de classes desbalanceadas (SMOTE)
- **joblib** - SerializaÃ§Ã£o de modelos

### API & Web
- **FastAPI** - Framework REST moderno e rÃ¡pido
- **uvicorn** - Servidor ASGI de alta performance
- **pydantic** - ValidaÃ§Ã£o de dados com type hints

### Monitoramento & Observabilidade
- **Loguru 0.7.0+** - Logging estruturado com cores e rotaÃ§Ã£o
- **Prometheus 2.47+** - Coleta e armazenamento de mÃ©tricas
  - `prometheus-client` - Cliente Python
  - `prometheus-fastapi-instrumentator` - InstrumentaÃ§Ã£o automÃ¡tica
- **Grafana 10.2+** - VisualizaÃ§Ã£o e dashboards
  - Auto-provisioning de datasources
  - 4 dashboards prÃ©-configurados

### Infrastructure
- **Docker** - ContainerizaÃ§Ã£o
- **Docker Compose** - OrquestraÃ§Ã£o (opcional)
- **Git** - Controle de versÃ£o

## ğŸ“Š VariÃ¡veis do Dataset

Consulte o arquivo `data/docs/bank_churn_dict.csv` para descriÃ§Ã£o detalhada das variÃ¡veis.

**Principais features:**
- VariÃ¡veis numÃ©ricas: `idade`, `saldo_conta`, `salario_estimado`, `escore_credito`
- VariÃ¡veis categÃ³ricas: `pais`, `genero`, `cartao_credito`
- VariÃ¡veis ordinais: `anos_cliente`, `numero_produtos`
- Target: `saiu` (0 = nÃ£o saiu, 1 = saiu)

## ğŸš€ Como Usar

### InstalaÃ§Ã£o

1. Clone o repositÃ³rio:
```bash
git clone https://github.com/jaisonschmidt/mlops-docker-template.git
cd mlops-docker-template
```

2. Crie e ative um ambiente virtual Python:

**Linux/Mac:**
```bash
python3 -m venv venv
source venv/bin/activate
```

**Windows:**
```bash
python -m venv venv
venv\Scripts\activate
```

3. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

> **Nota:** Para desativar o ambiente virtual, use o comando `deactivate`

### Treinamento do Modelo

Execute o script de treinamento para criar o modelo inicial:

```bash
python src/treinamento.py
```

**Entradas:**
- `data/raw/dados_treino.csv`

**SaÃ­das:**
- `models/pipeline_modelo_treinado.joblib` - Pipeline completo do modelo
- `outputs/metricas_desempenho_evasao.csv` - MÃ©tricas de desempenho

### PrediÃ§Ã£o em Novos Dados

Execute o script de prediÃ§Ã£o para classificar novos clientes:

```bash
python src/predicao.py
```

**Entradas:**
- `data/raw/dados_novos_1.csv` (ou `dados_novos_2.csv`)
- `models/pipeline_modelo_treinado.joblib`

**SaÃ­das:**
- `outputs/predicoes.csv` - Probabilidades e classificaÃ§Ã£o de risco

**ClassificaÃ§Ã£o de Risco:**
- ğŸŸ¢ **Risco muito alto**: Probabilidade > 90%
- ğŸŸ¡ **Risco alto**: Probabilidade > 70%
- ğŸŸ  **Risco moderado**: Probabilidade > 50%
- ğŸ”´ **Risco baixo**: Probabilidade < 50%

## ğŸ³ Usando Docker

**DocumentaÃ§Ã£o Docker:** [DOCKER_API.md](DOCKER_API.md)

> **Nota para usuÃ¡rios Windows:**
> - No **PowerShell**, use `${PWD}` ao invÃ©s de `$(pwd)`
> - No **CMD**, use `%cd%` ao invÃ©s de `$(pwd)`
> 
> Exemplo PowerShell: `docker run --rm -v ${PWD}/data:/app/data ...`

### 1. Treinar o Modelo com Docker

Para treinar o modelo usando Docker, execute os seguintes comandos:

```bash
# Build da imagem Docker
docker build -t mlops-churn:latest .

# Executar o treinamento
docker run --rm \
  -v $(pwd)/data:/app/data \
  -v $(pwd)/models:/app/models \
  -v $(pwd)/outputs:/app/outputs \
  mlops-churn:latest python src/treinamento.py
```

**ExplicaÃ§Ã£o dos parÃ¢metros:**
- `--rm` - Remove o container automaticamente apÃ³s a execuÃ§Ã£o
- `-v $(pwd)/data:/app/data` - Monta o diretÃ³rio de dados
- `-v $(pwd)/models:/app/models` - Monta o diretÃ³rio de modelos (para salvar o modelo treinado)
- `-v $(pwd)/outputs:/app/outputs` - Monta o diretÃ³rio de saÃ­das (para salvar mÃ©tricas)

**Arquivos gerados:**
- `models/pipeline_modelo_treinado.joblib` - Modelo treinado
- `outputs/metricas_desempenho_evasao.csv` - MÃ©tricas de desempenho

### 2. Fazer PrediÃ§Ãµes com Docker

Para executar prediÃ§Ãµes em novos dados usando Docker:

```bash
# Executar prediÃ§Ãµes
docker run --rm \
  -v $(pwd)/data:/app/data \
  -v $(pwd)/models:/app/models \
  -v $(pwd)/outputs:/app/outputs \
  mlops-churn:latest python src/predicao.py
```

**PrÃ©-requisitos:**
- Modelo jÃ¡ treinado em `models/pipeline_modelo_treinado.joblib`
- Dados novos em `data/raw/dados_novos_1.csv` (ou `dados_novos_2.csv`)

**Arquivo gerado:**
- `outputs/predicoes.csv` - PrediÃ§Ãµes com probabilidades e classificaÃ§Ã£o de risco

### 3. Subir a API com Docker

Para executar a API de consulta de prediÃ§Ãµes com Docker:

```bash
# Build da imagem da API
docker build -f Dockerfile.api -t api-churn:latest .

# Executar a API
docker run -d \
  -p 8000:8000 \
  --name api-churn-container \
  -v $(pwd)/outputs:/app/outputs:ro \
  --restart unless-stopped \
  api-churn:latest
```

**ExplicaÃ§Ã£o dos parÃ¢metros:**
- `-d` - Executa em background (modo daemon)
- `-p 8000:8000` - Mapeia a porta 8000 do container para a porta 8000 do host
- `--name api-churn-container` - Define o nome do container
- `-v $(pwd)/outputs:/app/outputs:ro` - Monta o diretÃ³rio de prediÃ§Ãµes (read-only)
- `--restart unless-stopped` - Reinicia automaticamente o container se ele parar

**Acessar a API:**
- **Base URL**: http://localhost:8000
- **DocumentaÃ§Ã£o interativa (Swagger)**: http://localhost:8000/docs
- **Health check**: http://localhost:8000/health

**Gerenciar o container da API:**

```bash
# Ver logs
docker logs -f api-churn-container

# Parar a API
docker stop api-churn-container

# Iniciar a API novamente
docker start api-churn-container

# Remover o container
docker rm -f api-churn-container
```

**Testar a API:**

```bash
# Health check
curl http://localhost:8000/health

# Consultar risco de churn de um cliente
curl http://localhost:8000/churn/15590146

# Listar clientes com alto risco
curl "http://localhost:8000/churn/todas/predicoes?risco_minimo=0.8&limite=10"
```

### Script Auxiliar para Docker

Para facilitar o gerenciamento da API com Docker, use o script auxiliar:

```bash
# Tornar o script executÃ¡vel (apenas uma vez)
chmod +x docker-api.sh

# Build da imagem
./docker-api.sh build

# Iniciar a API
./docker-api.sh run

# Ver status
./docker-api.sh status

# Ver logs
./docker-api.sh logs

# Testar a API
./docker-api.sh test

# Parar a API
./docker-api.sh stop

# Rebuild completo
./docker-api.sh rebuild
```

ğŸ“– **DocumentaÃ§Ã£o completa:**
- **API**: [API_CHURN_README.md](API_CHURN_README.md)
- **Docker**: [DOCKER_API.md](DOCKER_API.md)

### Exemplo Completo: Fluxo de Trabalho com Docker

Aqui estÃ¡ um exemplo completo do fluxo de trabalho usando Docker:

```bash
# 1. Build da imagem principal
docker build -t mlops-churn:latest .

# 2. Treinar o modelo
docker run --rm \
  -v $(pwd)/data:/app/data \
  -v $(pwd)/models:/app/models \
  -v $(pwd)/outputs:/app/outputs \
  mlops-churn:latest python src/treinamento.py

# 3. Fazer prediÃ§Ãµes
docker run --rm \
  -v $(pwd)/data:/app/data \
  -v $(pwd)/models:/app/models \
  -v $(pwd)/outputs:/app/outputs \
  mlops-churn:latest python src/predicao.py

# 4. Build da imagem da API
docker build -f Dockerfile.api -t api-churn:latest .

# 5. Subir a API
docker run -d \
  -p 8000:8000 \
  --name api-churn-container \
  -v $(pwd)/outputs:/app/outputs:ro \
  api-churn:latest

# 6. Testar a API
curl http://localhost:8000/health
curl http://localhost:8000/churn/15590146

# 7. Ver logs da API
docker logs -f api-churn-container

# 8. Parar e remover a API quando terminar
docker stop api-churn-container
docker rm api-churn-container
```

### Resumo de Comandos Docker

| Tarefa | Comando |
|--------|---------|
| **Build imagem principal** | `docker build -t mlops-churn:latest .` |
| **Treinar modelo** | `docker run --rm -v $(pwd)/data:/app/data -v $(pwd)/models:/app/models -v $(pwd)/outputs:/app/outputs mlops-churn:latest python src/treinamento.py` |
| **Fazer prediÃ§Ãµes** | `docker run --rm -v $(pwd)/data:/app/data -v $(pwd)/models:/app/models -v $(pwd)/outputs:/app/outputs mlops-churn:latest python src/predicao.py` |
| **Build imagem API** | `docker build -f Dockerfile.api -t api-churn:latest .` |
| **Subir API** | `docker run -d -p 8000:8000 --name api-churn-container -v $(pwd)/outputs:/app/outputs:ro api-churn:latest` |
| **Ver logs da API** | `docker logs -f api-churn-container` |
| **Parar API** | `docker stop api-churn-container` |
| **Remover API** | `docker rm -f api-churn-container` |

## ğŸ”„ Retreinamento do Modelo

### Retreinamento com Docker

Para retreinar o modelo com novos dados usando Docker:

```bash
# 1. Executar o script de retreinamento (combina datasets)
docker run --rm \
  -v $(pwd)/data:/app/data \
  mlops-churn:latest python src/retreinamento.py

# 2. Treinar o modelo com os dados combinados
docker run --rm \
  -v $(pwd)/data:/app/data \
  -v $(pwd)/models:/app/models \
  -v $(pwd)/outputs:/app/outputs \
  mlops-churn:latest python src/treinamento.py
```

### Retreinamento Local

Para retreinar o modelo com novos dados localmente:

### OpÃ§Ã£o 1: Usando o script de retreinamento (Recomendado)

```bash
# Retreinar com dados_novos_1.csv
python src/retreinamento.py

# Ou especificar outro arquivo
python src/retreinamento.py data/raw/dados_novos_2.csv

# Depois executar o treinamento
python src/treinamento.py
```

### OpÃ§Ã£o 2: Retreino manual

```bash
# No terminal Python ou script
import pandas as pd

# Combinar datasets
dados_treino = pd.read_csv("data/raw/dados_treino.csv")
dados_novos = pd.read_csv("data/raw/dados_novos_1.csv")
dados_combinados = pd.concat([dados_treino, dados_novos], ignore_index=True)
dados_combinados.to_csv("data/raw/dados_treino.csv", index=False)

# Executar treinamento
```

```bash
python src/treinamento.py
```

### OpÃ§Ã£o 3: Retreino incremental (em lotes)

Ã‰ possÃ­vel fazer retreino em lotes menores (ex: 32 em 32) para simular aprendizado contÃ­nuo.

## ğŸ“ˆ Pipeline de ML

O modelo implementa o seguinte pipeline:

1. **ImputaÃ§Ã£o de valores ausentes**
   - KNN Imputer para variÃ¡veis numÃ©ricas
   - Most Frequent para categÃ³ricas

2. **TransformaÃ§Ãµes**
   - Power Transform + Standard Scaler (numÃ©ricas)
   - One-Hot Encoding (categÃ³ricas)
   - Target Encoding (ordinais)
   - Polynomial Features (interaÃ§Ãµes)

3. **Balanceamento**
   - SMOTE para classes desbalanceadas

4. **Modelo**
   - Random Forest Classifier (1000 Ã¡rvores)
   - Tuned Threshold com otimizaÃ§Ã£o F2-score

## ğŸ“Š MÃ©tricas de AvaliaÃ§Ã£o

O modelo Ã© avaliado usando:
- **F1-Score** e **F2-Score** (weighted)
- **PrecisÃ£o** e **Recall** (weighted)
- **AUC-ROC**

ClassificaÃ§Ã£o de desempenho:
- âœ… Excelente: > 0.90
- ğŸ‘ Bom: > 0.80
- âš ï¸ AceitÃ¡vel: > 0.70
- âš¡ Fraco: > 0.60
- âŒ Ruim: < 0.60

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se livre para abrir issues ou pull requests.

## ğŸ‘¨â€ğŸ« Para Instrutores

### Estrutura PedagÃ³gica

Este projeto foi desenvolvido para ensino de MLOps seguindo 6 passos incrementais:

| Passo | TÃ³pico | DuraÃ§Ã£o | Objetivos |
|-------|--------|---------|-----------|
| **1** | PreparaÃ§Ã£o do Ambiente | 30min | Dependencies, configs |
| **2** | ImplementaÃ§Ã£o do Loguru | 45min | Structured logging |
| **3** | ImplementaÃ§Ã£o do Prometheus | 60min | Metrics collection |
| **4** | ImplementaÃ§Ã£o do Grafana | 90min | Dashboards, visualization |
| **5** | InstrumentaÃ§Ã£o ML | 45min | Model metrics |
| **6** | IntegraÃ§Ã£o e Testes | 60min | E2E testing |

**Total**: ~5.5 horas (pode ser dividido em 3 aulas de 2h)

### Commits Organizados

Cada passo possui um commit dedicado para facilitar o ensino incremental:

```bash
git log --oneline --graph
# * d0d92e3 feat: PASSO 6 - IntegraÃ§Ã£o, testes e documentaÃ§Ã£o
# * e808d6b feat: PASSO 5 - InstrumentaÃ§Ã£o de mÃ©tricas ML
# * 493064b feat: PASSO 4 - ImplementaÃ§Ã£o do Grafana
# * d4a4655 feat: PASSO 3 - ImplementaÃ§Ã£o do Prometheus
# * 231314c feat: PASSO 2 - ImplementaÃ§Ã£o do Loguru
# * f8ba800 feat: PASSO 1 - PreparaÃ§Ã£o do ambiente
```

### SugestÃµes de Aula

**Aula 1 - Fundamentos (2h)**
- Passos 1 e 2: Logging estruturado
- DiscussÃ£o: Por que monitoramento Ã© importante?

**Aula 2 - MÃ©tricas (2h)**  
- Passos 3 e 4: Prometheus e Grafana
- PrÃ¡tica: Criar queries PromQL

**Aula 3 - IntegraÃ§Ã£o (2h)**
- Passos 5 e 6: InstrumentaÃ§Ã£o e testes
- Projeto: Adicionar nova mÃ©trica personalizada

### ExercÃ­cios Propostos

1. **BÃ¡sico**: Adicionar nova mÃ©trica de "tempo de carregamento de modelo"
2. **IntermediÃ¡rio**: Criar dashboard personalizado com mÃ©tricas especÃ­ficas
3. **AvanÃ§ado**: Implementar alerta customizado com notificaÃ§Ã£o Slack
4. **Projeto**: Integrar com MLflow para tracking de experimentos

## ğŸ“Š HistÃ³rico de VersÃµes

- **v1.0** - Sistema MLOps completo com monitoramento
- **v0.3** - Adicionado Grafana e dashboards
- **v0.2** - Adicionado Prometheus e mÃ©tricas
- **v0.1** - API bÃ¡sica de churn

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob licenÃ§a MIT.

## ğŸ“§ Contato

Para dÃºvidas ou sugestÃµes, abra uma issue no repositÃ³rio.

---

**Desenvolvido com â¤ï¸ para ensino de MLOps**

> ğŸ’¡ **Dica para alunos**: Comece pelos tutoriais em `tutorial/` antes de mexer no cÃ³digo!